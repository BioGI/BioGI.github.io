<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="generator" content="scholpandoc">
  <meta name="viewport" content="width=device-width">
  
  <meta name="author" content="Farhad Behafarid and Ganesh Vijayakumar">
  <meta name="dcterms.date" content="2015-10-20">
  <title>Skype meeting with Balaji and Yanxing</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.7.1/modernizr.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.js"></script>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" href="css/ScholarlyMarkdown-BS3.css">
</head>
<body>
<div class="scholmd-container">
<div class="scholmd-main">
<div class="scholmd-content">
<header>
<h1 class="scholmd-title">Skype meeting with Balaji and Yanxing</h1>
<div class="scholmd-author">
Farhad Behafarid and Ganesh Vijayakumar
</div>
<div class="scholmd-date">20 Oct 2015</div>
</header>
<ol type="1">
<li>What features were only developed in the Couette code? (other than parallel particle tracking and polydisperse)</li>
</ol>
<ul>
<li>Updated qCalc</li>
<li>Parallel particle tracking and I/O for particles Yanxing had implemented some particle tracers. Balaji wrote his own and compared the lagrangian trajectories to Yanxing’s results.</li>
<li>Implemented Drug dissolution model</li>
<li>Original scalar BC in the Couette code was crap. Yanxing had developed this BC, while Gino had implemented it. Yanxing’s implementation is incorrect and doesn’t conserve scalar. Scalar flux BC is tricky.</li>
<li>Balaji validated it to the extent that Gino’s code produces the same peristalsis results as Yanxing’s code.</li>
<li>Set occlusion ratio to 1.0 and set the wall velocity. You should get a straight velocity profile and exact mass conservation.</li>
</ul>
<ol start="2" type="1">
<li>In particle dissolution model, it was assumed that particle size is small compared to the lattice mesh size. Increasing the mesh resolution (especially for fasting mode), what assumptions are becoming invalid?</li>
</ol>
<p>If the particle is larger than the mesh size, then the local particle concentration may become larger than the saturation concentration. This is not physical.</p>
<ol start="3" type="1">
<li>Was there any effort on running the Intestine code with polydisperse particle distribution?</li>
</ol>
<p>No. Intestine code doesn’t have the drug dissolution model.</p>
<ol start="4" type="1">
<li>What are the intestine domain dimensions (We got different values form Balaji’s code and Gino’s dissertation)</li>
</ol>
<p>No clear idea. Nobody has any details on this.</p>
<ol start="5" type="1">
<li>Could you please clarify the output in scalar-000*.dat. Here’s what we found in Output.f90 given by Balaji.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode fortran"><code class="sourceCode fortran"><span class="co">!Scalar</span>
<span class="fu">OPEN(</span><span class="dv">2472</span>,<span class="fu">FILE</span><span class="kw">=</span><span class="st">&#39;scalar-&#39;</span><span class="kw">//</span>sub<span class="kw">//</span><span class="st">&#39;.dat&#39;</span><span class="fu">)</span>
<span class="fu">WRITE(</span><span class="dv">2472</span>,<span class="st">&#39;(A100)&#39;</span><span class="fu">)</span> <span class="st">&#39;VARIABLES = &quot;iter&quot;, &quot;phiA&quot;, &quot;phiAS&quot;, &quot;phiAV&quot;, &quot;phiT-phiD&quot;, &quot;phiD&quot;, &quot;phA+phiD&quot;,&quot;phiAverage&quot;&#39;</span>
<span class="fu">WRITE(</span><span class="dv">2472</span>,<span class="fu">*)</span> <span class="st">&#39;ZONE F=POINT&#39;</span>
<span class="fu">WRITE(</span><span class="dv">2472</span>,<span class="st">&#39;(I8,7E25.15)&#39;</span><span class="fu">)</span> iter, <span class="fl">4.0_dbl</span><span class="kw">*</span>phiAbsorbed<span class="kw">*</span>zcf3, <span class="fl">4.0_dbl</span><span class="kw">*</span>phiAbsorbedS<span class="kw">*</span>zcf3, <span class="fl">4.0_dbl</span><span class="kw">*</span>phiAbsorbedV<span class="kw">*</span>zcf3,(phiTotal<span class="kw">-</span>phiDomain)<span class="kw">*</span>zcf3,<span class="fl">4.0_dbl</span><span class="kw">*</span>phiDomain<span class="kw">*</span>zcf3, (phiAbsorbed<span class="kw">+</span>phiDomain)<span class="kw">*</span>zcf3, phiAverage<span class="kw">*</span>zcf3</code></pre></div>
<p>Some of these quantities are multiplied by 4 and some are not. The factor of 4 is removed in the Couette code.</p>
<p>Probably the code was written for a quarter of the domain.</p>
<ol start="6" type="1">
<li>We tried to reproduce Gino’s results for the 3D intestine – Peristalsis case. We’re getting much faster absorption than Gino.</li>
</ol>
<p><code>@Balaji</code>: Have you tried to reproduce Gino’s results?</p>
<p>Balaji tried to make sure that Yanxing’s code and Gino’s code gave the same result for peristalsis. He did not try to match Gino’s result.</p>
<p><code>@Yanxing</code>: Gino’s thesis never mentions the grid resolution he used or the domain size and other parameters. Do you have the input file he used for any of his simulations?</p>
<p>No. Yanxing doesn’t have any input file that Gino used.</p>
<figure class="scholmd-float scholmd-figure" id="ginoPeristalsisReplicateAttempts">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./periodsTo90pAbsorption.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">1</span></span><span class="scholmd-caption-text">Attempts to reproduce Gino’s results for Peristalsis</span></figcaption></div>
</figure>
<ol start="7" type="1">
<li>Discussion of the multiple grid capability</li>
</ol>
<ul>
<li>How do you do this in parallel? Do you make sure the decomposition is such that the same area of the domain is decomposed into the same processor?</li>
</ul>
<p>Yanxing put all the coarse grid into 1 processor and then distribute the fine grid uniformly. Decomposition is done by hand.</p>
<ul>
<li><p>How about load balancing? Clearly the processors that contain multiple grids have to do more work than others.</p></li>
<li><p>Interpolation – Is the order of interpolation related to the order of accuracy? Do we do trilinear interpolation or anything else? Yu et. al. talk about cubic spline interpolation.</p></li>
</ul>
<p>Yanxing uses the same interpolation as in Yu’s paper. Interpolation is only required when going from coarse to find grid.</p>
<ol start="8" type="1">
<li>Discussion of code given by Yanxing today</li>
</ol>
<p>Yanxing gave us a code today that models the scalar dissolution from a freely suspended sphere in the shear flow. It also contains the important multigrid capability. To run this code, you first need to construct the connection relationship of the sub-domains by running conn.exe. The code is currently configured to run on 144 processors. The <code>conn</code> files specify the connectivity between different processors. Right now, the decomposition is non-trivial and have to make sure that the boundaries are right.</p>
<ol start="9" type="1">
<li>Any other codes that Yanxing has?</li>
</ol>
<p>Yanxing sent us another 3D cavity code folder which contains different domain decompositions (with 1,2,4 and 8 subdomains/processors). The scalar is released at the top lid. This code does not have the multi-grid, but it provides a clear picture of the parallelization.</p>
<div class="references">

</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
      processClass: "math"
    },
    TeX: {
        TagSide: "left",
        TagIndent: "1.2em",
        equationNumbers: {
            autoNumber: "AMS"
        },
        Macros: {
            ensuremath: ["#1",1],
            textsf: ["\\mathsf{\\text{#1}}",1],
            texttt: ["\\mathtt{\\text{#1}}",1]
        }
    },
    "HTML-CSS": { 
        scale: 100,
        availableFonts: ["TeX"], 
        preferredFont: "TeX",
        webFont: "TeX",
        imageFont: "TeX",
        EqnChunk: 1000
    }
});
</script>
</div>
</body>
</html>
