<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="generator" content="scholpandoc">
  <meta name="viewport" content="width=device-width">
  
  <meta name="author" content="Ganesh Vijayakumar">
  <title>My attempt at implementing a multi-block method in the intestine code</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.7.1/modernizr.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.js"></script>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" href="css/ScholarlyMarkdown-BS3.css">
</head>
<body>
<div class="scholmd-container">
<div class="scholmd-main">
<div class="scholmd-content">
<header>
<h1 class="scholmd-title">My attempt at implementing a multi-block method in the intestine code</h1>
<div class="scholmd-author">
Ganesh Vijayakumar
</div>
<div class="scholmd-date">21 Oct 2015 - present</div>
</header>
<p>I’ll document my attempts at implementing a multi-block method in the intestine code.</p>
<p>The main reason for implemeting a multi-block method in the intestine code is to be able to simulate fasting states, where the occlusion ratio for intestinal motility can go really small. The occlusion ratio is not quite the ratio of the occluded diameter to the total diameter of the domain. 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation*}
\begin{aligned}
a &amp;= \frac{0.5 \; D}{ 2 - (\epsilon/a)} \\
\rightarrow \frac{a}{0.5 D} &amp;= \frac{1}{ 2 - (\epsilon/a)} \\
\rightarrow \frac{\epsilon}{0.5 D} &amp;= \frac{\epsilon}{a} \frac{a}{0.5 D} =  \frac{\epsilon}{a} \frac{1}{ 2 - (\epsilon/a)}
\end{aligned}
\end{equation*}
\]</span>
 When <span class="math scholmd-math-inline">\(\epsilon/a \ll 2\)</span>, <span class="math scholmd-math-inline">\(\epsilon/(0.5D)\)</span> will become half of <span class="math scholmd-math-inline">\((\epsilon/a)\)</span>.</p>
<p>A rule of thumb is that the the occluded region should be resolved with about <span class="math scholmd-math-inline">\(\sim 10\)</span> cells. The estimate of the maximum gut diameter we’ve been using so far is <span class="math scholmd-math-inline">\(D = 0.005m\)</span>. Lets say this is resolved with a 100 cells in the <span class="math scholmd-math-inline">\(x\)</span> and <span class="math scholmd-math-inline">\(y\)</span> directions. The resolution will be <span class="math scholmd-math-inline">\(\Delta x = 0.005/100 = 5 \times 10^{-5}m\)</span>. Table <span class="scholmd-crossref"><a href="#table:resolutionRequirements">(1)</a></span> shows that the resolution requirements increase severely as the occlusion ratio is dropped. It may not be feasible to acheive a reduction of the grid spacing of <span class="math scholmd-math-inline">\(\sim O(20-200)\)</span> times with just two grids. I suspect that we will need atleast 3 grids with a reduction ratio of <span class="math scholmd-math-inline">\(m-5\)</span> to simulate the occlusion ratio of 0.01 and may be 4 grids with a similar reduction ratio to simulate the occlusion ratio of 0.001.</p>
<figure class="scholmd-float scholmd-table-float" id="table:resolutionRequirements">
<div class="scholmd-float-content"><table>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math scholmd-math-inline">\(\epsilon/a\)</span></th>
<th style="text-align: left;"><span class="math scholmd-math-inline">\(\epsilon/R\)</span></th>
<th style="text-align: left;"><span class="math scholmd-math-inline">\(\Delta x_f\)</span></th>
<th style="text-align: left;">Ratio <span class="math scholmd-math-inline">\(\Delta x_c / \Delta x_f\)</span></th>
<th style="text-align: left;">$nx_f, <span class="math scholmd-math-inline">\(ny_f = 0.1 D / \Delta x_f\)</span></th>
<th style="text-align: left;"><span class="math scholmd-math-inline">\(nz_f = L/\Delta x_f\)</span></th>
<th style="text-align: left;"><span class="math scholmd-math-inline">\(nx_f \times ny_f \times nz_f\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0.5</td>
<td style="text-align: left;">0.32</td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(1.667 \times 10^{-4}\)</span>m</td>
<td style="text-align: left;">0.3</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">0.1</td>
<td style="text-align: left;">0.0527</td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(2.631 \times 10^{-5}\)</span>m</td>
<td style="text-align: left;">1.9</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">380</td>
<td style="text-align: left;">137k</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0.01</td>
<td style="text-align: left;">0.005</td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(2.512 \times 10^{-6}\)</span>m</td>
<td style="text-align: left;">20</td>
<td style="text-align: left;">200</td>
<td style="text-align: left;">4000</td>
<td style="text-align: left;">157M</td>
</tr>
<tr class="even">
<td style="text-align: left;">0.001</td>
<td style="text-align: left;">0.0005</td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(2.501 \times 10^{-7}\)</span>m</td>
<td style="text-align: left;">200</td>
<td style="text-align: left;">2000</td>
<td style="text-align: left;">40000</td>
<td style="text-align: left;">159B</td>
</tr>
</tbody>
</table></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Table</span><span class="scholmd-caption-head-label">1</span></span><span class="scholmd-caption-text">Demonstration of resolution requirement in the occluded region as the occlusion ratio <span class="math scholmd-math-inline">\(\epsilon/a\)</span> is reduced.</span></figcaption></div>
</figure>
<h2 id="how-to-design-the-extent-of-the-fine-mesh">How to design the extent of the fine mesh</h2>
<p>Let’s say that we require only two grids. Figure <span class="scholmd-crossref"><a href="#multiblockDomainDecomposition">(1)</a></span> shows the proposed design of a slice of (<span class="math scholmd-math-inline">\(x=0\)</span> plane) a cylindrical computational domain and the fine mesh within.</p>
<figure class="scholmd-float scholmd-figure" id="multiblockDomainDecomposition">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/multiblockDomainDecomposition.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">1</span></span><span class="scholmd-caption-text">Proposed design of the computational domain and the fine mesh and it’s domain decomposition.</span></figcaption></div>
</figure>
<p>The rule of thumb reg. 10 grid points in the occluded region need to be applied uniformly across the entire gut. Thus, if the max diameter of the gut is resolved with 100 points, the inner 10% of the domain needs to be refined at all times as it would have less than 10 cells by definition. If the fine mesh has been designed according to the rule of thumb, the resolution requirements would start to become astronomical very quickly as shown in the last column in Table <span class="scholmd-crossref"><a href="#table:resolutionRequirements">(1)</a></span>.</p>
<h1 id="actual-design-of-the-multi-blockgrid-algorithm">Actual design of the multi-block/grid algorithm</h1>
<p>All these issues , not withstanding, I’m still going ahead with designing the multi-grid algorithm. I had to print out and study the Intestine code in detail. I’ll branch off the Intestine code and not the COuette code as I’m not sure of the readiness of this code to simulate intestinal motility. When Farhad makes the merge between the two codes, my mods to the Intestine code should transfer straight away to the merged code.</p>
<h2 id="diagrams-that-help-understanding-the-basics-of-the-intestine-3d-code">Diagrams that help understanding the basics of the intestine 3D code</h2>
<p>This will probably belong in it’s own section. But I’ll just make a brief description of the Intestine 3D code here.</p>
<p>Most of the LBM algorithm is fairly straight forward. The complicated parts involve the communication between processors to exchange information. This is first done by creating local arrays that are padded on the boundaries in each direction like so in <code>Setup.f90</code></p>
<pre class="sourceCode fortran"><code class="sourceCode fortran"><span class="co">! Distribution Functions</span>
<span class="kw">ALLOCATE</span>(f(<span class="dv">0</span>:NumDistDirs,<span class="dv">0</span>:nxSub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nySub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nzSub<span class="kw">+</span><span class="dv">1</span>),                        <span class="kw">&amp;</span>
fplus(<span class="dv">0</span>:NumDistDirs,<span class="dv">0</span>:nxSub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nySub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nzSub<span class="kw">+</span><span class="dv">1</span>))
<span class="co">! Velocity, Density</span>
<span class="kw">ALLOCATE</span>(u(<span class="dv">0</span>:nxSub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nySub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nzSub<span class="kw">+</span><span class="dv">1</span>),                                                      <span class="kw">&amp;</span>
v(<span class="dv">0</span>:nxSub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nySub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nzSub<span class="kw">+</span><span class="dv">1</span>),                                                      <span class="kw">&amp;</span>
w(<span class="dv">0</span>:nxSub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nySub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nzSub<span class="kw">+</span><span class="dv">1</span>))
<span class="kw">ALLOCATE</span>(rho(<span class="dv">0</span>:nxSub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nySub<span class="kw">+</span><span class="dv">1</span>,<span class="dv">0</span>:nzSub<span class="kw">+</span><span class="dv">1</span>))</code></pre>
<p>The numbering scheme for the density distribution function and the lattice velocity vectors are shown in Figure <span class="scholmd-crossref"><a href="#densityDistribution">(2)</a></span>.</p>
<figure class="scholmd-float scholmd-figure" id="densityDistribution">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./densityDistribution.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">2</span></span><span class="scholmd-caption-text">Numbering scheme of the density distribution directions and lattice velocity vectors in the Intestine 3D code.</span></figcaption></div>
</figure>
<p>Now for the complicated second part. The nodes on the boundaries of each processor could potentially interact with another processor in a variety of directions. To understand this, simply think of the information that a node on the faces, edges and corners of the processor boundaries. This is controlled by the temporary arrays <code>CDx, CDy and CDz</code> in the subroutine <code>SubDomainSetup</code> inside <code>Setup.f90</code>. Figure <span class="scholmd-crossref"><a href="#commDirs">(3)</a></span> shows the communication direction vector numbering scheme.</p>
<figure class="scholmd-float scholmd-figure" id="commDirs">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./commDirs.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">3</span></span><span class="scholmd-caption-text">Numbering scheme of the communication direction vectors in the Intestine 3D code.</span></figcaption></div>
</figure>
<p>This is then used to setup the array <code>SubID</code> that contains the neighboring processor in each communication direction through the subroutine <code>SetSubID</code>.</p>
<p>All of this information is then used to carefully setup the main arrays <code>msgSend</code> and <code>msgRecv</code> that is transferred across processors. There are a whole host of supporting arrays and variables that describe the structure of the the two main arrays and how to pack it before sending and unpack it after receiving. The optimization of this array is done pretty well and only information that is absolutely required is transferred. For instance, only certain components of the density distribution function is transferred depending upon the communication direction.</p>
<ul>
<li><code>OppCommDir</code></li>
<li><code>f_Comps</code></li>
<li><code>fSize</code></li>
<li><code>dsSize</code></li>
<li><code>uvwSize</code></li>
<li><code>YZ_FaceSize</code></li>
<li><code>ZX_FaceSize</code></li>
<li><code>XY_FaceSize</code></li>
<li><code>msgSize</code></li>
<li><code>f_SendSize</code></li>
<li><code>ds_SendSize</code></li>
<li><code>uvw_SendSize</code></li>
<li><code>total_SendSize</code></li>
<li><code>XY_SendIndex</code></li>
<li><code>YZ_SendIndex</code></li>
<li><code>XZ_SendIndex</code></li>
<li><code>X_SendIndex</code></li>
<li><code>Y_SendIndex</code></li>
<li><code>Z_SendIndex</code></li>
<li><code>Corner_SendIndex</code></li>
<li><code>XY_RecvIndex</code></li>
<li><code>YZ_RecvIndex</code></li>
<li><code>XZ_RecvIndex</code></li>
<li><code>X_RecvIndex</code></li>
<li><code>Y_RecvIndex</code></li>
<li><code>Z_RecvIndex</code></li>
<li><code>Corner_RecvIndex</code></li>
<li><code>CommDataStart_f</code></li>
<li><code>CommDataStart_rho</code></li>
<li><code>CommDataStart_phi</code></li>
<li><code>CommDataStart_u</code></li>
<li><code>CommDataStart_v</code></li>
<li><code>CommDataStart_w</code></li>
</ul>
<h2 id="current-plan-to-modify-the-intestine-code">Current plan to modify the Intestine code</h2>
<p>This is the current list of steps to modify the Intestine code to a multigrid code.</p>
<ol type="1">
<li>Copy <code>Setup, LBM, Geometry, ICBC, Parallel.f90</code> files into corresponding <code>_fine</code> files.</li>
<li>Change the variable names in these files to <code>_fine</code></li>
<li>In the mani <code>Geometry.f90</code> file, introduce a new type of node called <code>REFINEMESH</code>. Identify/Flag the required nodes as <code>REFINEMESH</code>.</li>
<li>Set the geometry parameters for the fine mesh in <code>Geometry_fine.f90</code> and the identify the outer nodes as <code>COARSEMESH</code>.</li>
<li>In the <code>Main.f90</code>, change the algorithm to include the sub-iterations for the fine mesh.</li>
<li>Introduce interpolation subroutines to transfer density distribution and other stuff between coarse and fine meshes.</li>
</ol>
<p>The progress on this can be tracked on the <a href="https://github.com/BioGI/Codes/commits/attemptedMultigrid">attemptedMultiGrid</a> branch of the Github repository.</p>
<h2 id="psuedo-code-for-multigrid-implementation-in-the-main-algorithm">Psuedo-code for multigrid implementation in the Main algorithm</h2>
<p>The current outline of the time-stepping in Main.f90 looks like this</p>
<pre class="sourceCode fortran"><code class="sourceCode fortran"><span class="kw">DO</span> iter <span class="kw">=</span> iter0<span class="kw">-</span><span class="dv">0_lng</span>,nt

      <span class="kw">CALL</span> AdvanceGeometry            <span class="co">! advance the geometry to the next time step [MODULE: Geometry]</span>
      <span class="kw">CALL</span> Collision                  <span class="co">! collision step [MODULE: Algorithm]</span>
      <span class="kw">CALL</span> MPI_Transfer               <span class="co">! transfer the data (distribution functions, density, scalar) [MODULE: Parallel]</span>

      <span class="kw">CALL</span> Stream                     <span class="co">! perform the streaming operation (with Lallemand 2nd order BB) [MODULE: Algorithm]</span>

      <span class="kw">CALL</span> Macro                      <span class="co">! calcuate the macroscopic quantities [MODULE: Algorithm]</span>

      <span class="kw">IF</span>(iter <span class="kw">.GE.</span> phiStart) <span class="kw">THEN</span>
          <span class="kw">CALL</span> Scalar             <span class="co">! calcuate the evolution of scalar in the domain [MODULE: Algorithm]</span>
      <span class="kw">END IF</span>

      <span class="kw">CALL</span> PrintFields                   <span class="co">! output the velocity, density, and scalar fields [MODULE: Output]</span>
      <span class="kw">CALL</span> PrintScalar                   <span class="co">! print the total absorbed/entering/leaving scalar as a function of time [MODULE: Output]</span>
      <span class="kw">CALL</span> PrintMass                     <span class="co">! print the total mass in the system (TEST)</span>
      <span class="kw">CALL</span> PrintVolume                   <span class="co">! print the volume in the system (TEST)</span>

      <span class="co">!   CALL PrintPeriodicRestart     ! print periodic restart files (SAFE GUARD) [MODULE: Output]</span>

      <span class="kw">CALL</span> PrintStatus              <span class="co">! print current status [MODULE: Output]</span>

      <span class="kw">CALL</span> MPI_BARRIER(MPI_COMM_WORLD,mpierr)       <span class="co">! synchronize all processing units before next loop [Intrinsic]</span>

<span class="kw">END DO</span></code></pre>
<p>Figure <span class="scholmd-crossref"><a href="#multiGridAlgorithm">(4)</a></span> shows the schematic of the multiblock algorithm for <code>gridRatio = 4</code>, i.e., the fine mesh has a resolution that is four times finer than the coarse mesh.</p>
<figure class="scholmd-float scholmd-figure" id="multiGridAlgorithm">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 65%">
<img src="./dualLattice/multiGridAlgorithm.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">4</span></span><span class="scholmd-caption-text">Schematic of the multiblock time-stepping algorithm. The resolution of the fine block is 4 times that of the coarse block.</span></figcaption></div>
</figure>
<p>Thus, the new time stepping psuedo-code should become</p>
<pre class="fortran90"><code>DO iter = iter0-0_lng,nt

      CALL AdvanceGeometry      ! advance the geometry to the next time step [MODULE: Geometry]
      CALL Stream           ! perform the streaming operation (with Lallemand 2nd order BB) [MODULE: Algorithm]
      CALL Macro            ! calcuate the macroscopic quantities [MODULE: Algorithm]
      CALL Scalar             ! calcuate the evolution of scalar in the domain [MODULE: Algorithm]
      CALL Collision                  ! collision step [MODULE: Algorithm]
      CALL MPI_Transfer               ! transfer the data (distribution functions, density, scalar) [MODULE: Parallel]

      CALL SpatialInterpolateToFineGrid      ! Interpolate required variables to fine grid
      DO subIter=1,ratio
          CALL AdvanceGeometry_Fine   ! Advance the geometry on the fine grid
          CALL TemporalInterpolateToFineGrid
          CALL Stream_Fine            ! Stream fine grid
          CALL Macro_Fine             ! Calculate Macro properties on fine grid
          CALL Scalar_Fine       ! Calculate Scalar stuff on fine grid
          CALL Collision_Fine     ! Collision step on the fine grid
          CALL MPI_Transfer_Fine  ! Transfer the data across processor boundaries on the fine grid
      END DO
      CALL InterpolateToCoarseGrid    ! Interpolate required variable to coarse grid

END DO</code></pre>
<h2 id="design-of-interpolation-from-coarse-mesh-to-fine-mesh">Design of Interpolation from coarse mesh to fine mesh</h2>
<p>In this section, I will describe the interface between a coarse and a fine mesh using an example. The coarse mesh has a 101 points in the x and y directions. Points 46-56 in both x and y directions are to be resolved by the fine mesh. The fraction of the total diameter resolved by the fine mesh will be <span class="math scholmd-math-inline">\(0.1D\)</span>. Figure <span class="scholmd-crossref"><a href="#designFineCoarseInterface">(5)</a></span> shows the interface between the coarse and the fine meshes.</p>
<figure class="scholmd-float scholmd-figure" id="designFineCoarseInterface">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 75%">
<img src="./dualLattice/multigridPlan_xy.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">x-y plane</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/multigridPlan_xz.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">x-z plane</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/multigridPlan_yz.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">y-z plane</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">5</span></span><span class="scholmd-caption-text">Design of the interface between the fine and coarse meshes for the multigrid algorithm.</span></figcaption></div>
</figure>
<h3 id="symmetric-cubic-spline-interpolation-in-space">Symmetric cubic spline interpolation in space</h3>
<p>A symmetric cubic spline interpolation procedure is used in all directions when interpolating from the coarse to fine mesh. For each fine mesh node, the nearest <code>lower</code> coarse mesh node <span class="math scholmd-math-inline">\(f_2\)</span> is identified such that the fine mesh node is always between <span class="math scholmd-math-inline">\(f_2\)</span> and <span class="math scholmd-math-inline">\(f_3\)</span> with <span class="math scholmd-math-inline">\(0 \le s &lt; 1\)</span> as shown in Fig. <span class="scholmd-crossref"><a href="#symmetricCubicSplineInterpolation">(6)</a></span>.</p>
<figure class="scholmd-float scholmd-figure" id="symmetricCubicSplineInterpolation">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 75%">
<img src="./dualLattice/cubicSplineInterpolation.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">6</span></span><span class="scholmd-caption-text">Design of cubic spline spatial interpolation scheme to transfer data from the coarse to the fine mesh.</span></figcaption></div>
</figure>
<h3 id="second-order-interpolation-in-time">Second order interpolation in time</h3>
<p>A second order interpolation procedure is used interpolating from the coarse to fine mesh in time. The data at the fine mesh is always wanted between time <span class="math scholmd-math-inline">\(t_n\)</span> and <span class="math scholmd-math-inline">\(t_{n+1}\)</span> as shown in Fig. <span class="scholmd-crossref"><a href="#multiGridAlgorithm">(4)</a></span>.</p>
<figure class="scholmd-float scholmd-figure" id="secondOrderTimeInterpolation">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 75%">
<img src="./dualLattice/secondOrderTimeInterpolation.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">7</span></span><span class="scholmd-caption-text">Design of second order temporal interpolation scheme to transfer data from the coarse to the fine mesh.</span></figcaption></div>
</figure>
<h3 id="special-cases---interference-of-wall-with-interpolation-from-coarse-to-fine-mesh">Special cases - interference of wall with interpolation from coarse to fine mesh</h3>
<p>When the intestine wall goes through the interface between the coarse to the fine mesh, the</p>
<pre class="fortran90"><code>FUNCTION spatialInterpolate(f1,f2,f3,f4,n1,n2,n3,n4,s)

!!!Symmetric Cubic spline temporal interpolation 

  REAL(dbl) :: f1, f2, f3, f4, s
  INTEGER   :: n1,n2,n3,n4
  REAL(dbl) :: spatialInterpolate
  REAL(dbl) :: aHat, bHat, cHat, dHat

  if (n3 .eq. SOLID) then
     if (n2 .ne. SOLID) then
        spatialInterpolate = spatialExtrapolate_n1n2(f1,f2,s)
     else
        spatialInterpolate = 0.0
     end if
     
  else if (n2 .eq. SOLID) then
     spatialInterpolate = spatialExtrapolate_n3n4(f3,f4,s)
     
  else if ( (n1 .ne. SOLID) .and. (n4 .eq. SOLID) ) then
     spatialInterpolate = spatialInterpolate_n1n2n3(f1,f2,f3,s)

  else if ( (n1 .eq. SOLID) .and. (n4 .ne. SOLID) ) then
     spatialInterpolate = spatialInterpolate_n2n3n4(f2,f3,f4,s)
     
  else if ( (n1 .eq. SOLID) .and. (n4 .eq. SOLID) ) then
     spatialInterpolate = spatialInterpolate_n2n3(f2,f3,s)

  else if ( (n1 .ne. SOLID) .and. (n2 .ne. SOLID) .and. (n3 .ne. SOLID) .and. (n4 .ne. SOLID) ) then
     spatialInterpolate = spatialInterpolateAllFour(f1,f2,f3,f4,s)
  end if
   
  RETURN
  
END FUNCTION spatialInterpolate</code></pre>
<h1 id="design-of-mesh-and-conversion-factors">Design of mesh and conversion factors</h1>
<p>It turns out that the relaxation parameter <span class="math scholmd-math-inline">\(\tau\)</span> cannot be 1.0 for both coarse and fine meshes. This has to do with the conversion/interpolation between the coarse and the fine meshes as descirbed in <a href="./lbmBasics.html#multi-grid-scheme">lbmBasics.html</a>. Hence the design of the mesh requires some thought. Lets say <span class="math scholmd-math-inline">\(\tau_c = 1.5\)</span>, with a grid ratio of <span class="math scholmd-math-inline">\(m = 4\)</span>. Then, 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation*}
\begin{aligned}
\tau_f &amp;= \frac{1}{2} + m \left ( \tau_c - \frac{1}{2} \right \\
&amp;= \frac{1}{2} + 4.0 \left ( 0.75 - \frac{1}{2} \right
&amp;= 4.5
\end{aligned}
\end{equation*}
\]</span>
 The conversion factors for each mesh will be</p>
<figure class="scholmd-float scholmd-table-float" id="table:meshDesign">
<div class="scholmd-float-content"><table>
<thead>
<tr class="header">
<th style="text-align: left;">Coarse mesh</th>
<th style="text-align: left;">Fine mesh</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math scholmd-math-inline">\(\nu_L = \frac{2 \times 1.5 - 1}{6} = 0.08333\)</span></td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(\nu_L = \frac{2 \times 4.5 - 1}{6} = 0.333333\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math scholmd-math-inline">\(x_{cf} = y_{cf} = z_{cf} = 1.2 \times 10^{-4}m\)</span></td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(x_{cf} = y_{cf} = z_{cf} = 0.3 \times 10^{-4}m\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math scholmd-math-inline">\(t_{cf} = \nu_L \frac{x_{cf} x_{cf}}{\nu} = 5e-4s\)</span></td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(t_{cf} = \nu_L \frac{x_{cf} x_{cf}}{\nu} = 1.25e-4s\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math scholmd-math-inline">\(v_{cf} = \frac{x_{cf}}{t_{cf}} = 0.24 m/s\)</span></td>
<td style="text-align: left;"><span class="math scholmd-math-inline">\(v_{cf} = \frac{x_{cf}}{t_{cf}} = 0.24 m/s\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Wave speed = <span class="math scholmd-math-inline">\(\frac{0.004}{0.24}\)</span> = 0.016667</td>
<td style="text-align: left;">Wave speed = <span class="math scholmd-math-inline">\(\frac{0.004}{0.24}\)</span> = 0.016667</td>
</tr>
<tr class="even">
<td style="text-align: left;">Reynolds number lattice = <span class="math scholmd-math-inline">\(\frac{0.016667 \times 50 \times 50}{0.08333 \times 200} = 2.5\)</span></td>
<td style="text-align: left;">Reynolds number lattice = <span class="math scholmd-math-inline">\(\frac{0.016667 \times 200 \times 200}{0.333333 \times 800} = 2.5\)</span></td>
</tr>
</tbody>
</table></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Table</span><span class="scholmd-caption-head-label">2</span></span><span class="scholmd-caption-text">Design of mesh and conversion factors for the coarse and fine mesh</span></figcaption></div>
</figure>
<h1 id="preliminary-validation-results">Preliminary validation results</h1>
<p>Comparing single lattice to dual lattice in a pure peristalsis case with occlusion ratio <span class="math scholmd-math-inline">\(= 0.1\)</span>. Single lattice has same resolution as coarse mesh on dual lattice. The grid ratio between coarse and fine meshes on the dual lattice is 4. The scalar initial condition is <span class="math scholmd-math-inline">\(\phi = 1\)</span> on a line running through the center of the domain.</p>
<figure class="scholmd-float scholmd-figure" id="singleLattice1XgridRatio4PressureA">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0000000_vizSingleLattice1X_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(a) t=0s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0000000_vizDualLattice_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(b) t=0s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0003000_vizSingleLattice1X_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(c) t=6s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0003000_vizDualLattice_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(d) t=6s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0006000_vizSingleLattice1X_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(e) t=12s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0006000_vizDualLattice_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(f) t=12s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0009000_vizSingleLattice1X_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(g) t=18s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0009000_vizDualLattice_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(h) t=18s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0012000_vizSingleLattice1X_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(i) t=24s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0012000_vizDualLattice_P.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(j) t=24s</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">8</span></span><span class="scholmd-caption-text">Comparison of evolution of flow field between single and dual lattice algorithm for a pure peristalsis case (occlusion ratio = 0.1) through pressure contours. (a),(c),(e),(g),(i) Single lattice algorithm; (d)-(j) Dual lattice algorithm.</span></figcaption></div>
</figure>
<figure class="scholmd-float scholmd-figure" id="singleLattice1XgridRatio4ScalarA">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0000000_vizSingleLattice1X_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(a) t=0s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0000000_vizDualLattice_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(b) t=0s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0003000_vizSingleLattice1X_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(c) t=6s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0003000_vizDualLattice_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(d) t=6s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0006000_vizSingleLattice1X_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(e) t=12s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0006000_vizDualLattice_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(f) t=12s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0009000_vizSingleLattice1X_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(g) t=18s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0009000_vizDualLattice_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(h) t=18s</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/singleLattice1X/t0012000_vizSingleLattice1X_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(i) t=24s</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/gridRatio4/t0012000_vizDualLattice_phi.jpg" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">(j) t=24s</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">9</span></span><span class="scholmd-caption-text">Comparison of evolution of flow field between single and dual lattice algorithm for a pure peristalsis case (occlusion ratio = 0.1) through contoursof scalar. (a),(c),(e),(g),(i) Single lattice algorithm; (d)-(j) Dual lattice algorithm.</span></figcaption></div>
</figure>
<p>It’s hard to distinguish between the two algorithms using the pressure contours in Fig. <span class="scholmd-crossref"><a href="#singleLattice1XgridRatio4PressureA">(8)</a></span> and contours of the scalar in Fig. <span class="scholmd-crossref"><a href="#singleLattice1XgridRatio4ScalarA">(9)</a></span>. Fig. <span class="scholmd-crossref"><a href="#singleLattice1XgridRatio4ScalarAbsorbed">(10)</a></span> compares the scalar absorbed over time computed using the different algorithms. This includes a double counting of the scalar absorbed in the interface region between the two meshes in the Dual Lattice algorithm. This is corrected in the next section.</p>
<figure class="scholmd-float scholmd-figure" id="singleLattice1XgridRatio4ScalarAbsorbed">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 33%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p1/scalarAbsorbed.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">occlusion ratio = 0.1</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 33%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p25/scalarAbsorbed.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">occlusion ratio = 0.25</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 33%">
<img src="./dualLattice/testResults/peristalsis/occlusion0p5/scalarAbsorbed.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">occlusion ratio = 0.5</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">10</span></span><span class="scholmd-caption-text">Comparison of scalar absorbed over time between single and dual lattice algorithm for a pure peristalsis case (occlusion ratio = 0.1,0.25,0.5).</span></figcaption></div>
</figure>
<h1 id="avoiding-double-counting-of-scalar">Avoiding double counting of scalar</h1>
<p>The test for avoiding the double counting of scalar is to run the LBM code (both single and dual lattice) for 1 time step with a prescribed scalar profile and gradient at the surface of a prescribed geometry. The prescribed geometry is a straight tube with a radius of <span class="math scholmd-math-inline">\(r=0.000671m\)</span>, such that the wall goes through the interface in the dual lattice algorithm. The prescribed scalar profile is linear in <span class="math scholmd-math-inline">\(r\)</span> such that <span class="math scholmd-math-inline">\(\phi=1\)</span> at the center and <span class="math scholmd-math-inline">\(\phi=0\)</span> at the wall. Thus, <span class="math scholmd-math-inline">\(\phi = 1 - r/0.000671\)</span>. 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation}
\label{calcScalarAbsorbedOverOneTimeStep}
\begin{aligned}
\left . \frac{\partial \phi}{ \partial n}  \right |_{wall} &amp;= -\frac{1}{0.000671} mol/m^4 \\
\textrm{Scalar flux at wall } &amp;= -D_m \left . \frac{\partial \phi}{ \partial n}  \right |_{wall} = -4.8 \times 10^{-8} \frac{-1}{0.000671} = 7.15 \times 10^{-5} mol/m^2 s \\
\textrm{Area of tube } &amp;= 2 \; \pi \; r \; L = 2 \pi \times 0.000671 \times 0.012 = 5.0592208093410036 \times 10^{-5} m^2 \\
\textrm{Time step } \Delta t &amp;= 2 \times 10^{-3} s \\
\textrm{Mol absorbed over 1 time step } &amp;= (7.15 \times 10^{-5}) \times (5.0592208093410036 \times 10^{-5}) \times (2 \times 10^{-3}) = 7.23823 \times 10^{-12} mol \\
\textrm{Total scalar in the domain } &amp;= L \int_0^R (2 \pi \; r) \; (1 - r/R) \; dr = L \; \pi \left ( R^2 - \frac{2 \; R^2}{3} \right ) = L \frac{\pi R^2}{3} = 5.657895 \times 10^{-9} mol
\end{aligned}
\end{equation}
\]</span>
 Fig. <span class="scholmd-crossref"><a href="#scalarAbsorbedTestr0p000671m">(11)</a></span> compares the scalar absorbed computed using the single and dual lattice algorithms with the analytical solution presented above. The dual lattice algorithm gives the same results as the single lattice algorithm to the last decimal place. However, the trend of scalar absorbed is not monotonous with grid refinement. One hypothesis for this is the way <span class="math scholmd-math-inline">\(q\)</span> is arbitrarily set to 0.25 if it’s less than 0.25 in the computation of the scalar boundary condition.</p>
<figure class="scholmd-float scholmd-figure" id="scalarAbsorbedTestr0p000671m">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/testResults/scalarAbsorbedTest/scalarAbsorbedTestr0p000671m.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">11</span></span><span class="scholmd-caption-text">Comparison of scalar absorbed over <span class="math scholmd-math-inline">\(\Delta t = 2 \times 10^{-3}s\)</span> for a cylinder of radius <span class="math scholmd-math-inline">\(r = 0.000671m\)</span> with the single and dual lattice algorithms. The straight line is the analytical solution.</span></figcaption></div>
</figure>
<p>While this test was originally intended to test the double counting avoidance procedure for the scalar in the domain and the scalar absorbed, I found that the intestine wall never actually enters the coarse mesh such that an active coarse mesh node (i.e. a node where the computation actually takes place) is adjacent to the wall.</p>
<figure class="scholmd-float scholmd-figure" id="avoidDoubleCountingScalarAbsorption">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/avoidDoubleCountingScalarAbsorption.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">12</span></span><span class="scholmd-caption-text">Scheme of flagging fine mesh nodes that intersect coarse mesh nodes to avoid double counting scalar that is absorbed at the wall when it goes through the interface between the two meshes.</span></figcaption></div>
</figure>
<p>Fig. <span class="scholmd-crossref"><a href="#avoidDoubleCountingScalarAbsorption">(12)</a></span> shows the procedure for flagging fine mesh nodes that intersect coarse mesh nodes to avoid double counting scalar that is absorbed at the wall when it goes through the interface between the two meshes. This has to be done afresh every coarse mesh time step whenever the scalar absorbed computation is done over the coarse mesh. The test performed in Fig. <span class="scholmd-crossref"><a href="#scalarAbsorbedTestStraightTube">(13)</a></span> and Eqn. <span class="scholmd-crossref"><span class="math scholmd-math-inline">\(\eqref{calcScalarAbsorbedOverOneTimeStep}\)</span></span> is repeated for cylinders of varying radius. Fig. <span class="scholmd-crossref"><a href="#scalarAbsorbedTestStraightTube">(13)</a></span> shows that the dual lattice algorithm performs no worse than the single lattice algorithm in computing the scalar absorbed through the surface. Also, the scalar absorbed in the dual lattice algorithm follows the single lattice 1X and 4X results respectively at low and high values of the cylinder radius compared to a cylinder going through the mesh interface location.</p>
<figure class="scholmd-float scholmd-figure" id="scalarAbsorbedTestStraightTube">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/testResults/scalarAbsorbedTest/straightTubeTestsScalarAbsorbed.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">a</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/testResults/scalarAbsorbedTest/straightTubeTestsScalarAbsorbedZoom.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">b</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">13</span></span><span class="scholmd-caption-text">Comparison of scalar absorbed over <span class="math scholmd-math-inline">\(\Delta t = 2 \times 10^{-3}s\)</span> for a cylinder of varying radius with the single and dual lattice algorithms. The straight line is the analytical solution. (a) Full range of radii; (b) Zoomed in.</span></figcaption></div>
</figure>
<p>While the fine mesh nodes are flagged to avoid double counting of the scalar absorbed, the inverse approach is adopted for computing the total amount of scalar in the domain. This flagging procedure however, has to be done only at the beginning of the code once. The test for avoiding the double counting in this case is to compute the total scalar in the domain (for a uniform scalar distribution <span class="math scholmd-math-inline">\((\phi=1)\)</span>) per unit disk area and plot the result as a function of the radius. The analytical solution is a straight line equal to the length of the domain. Again, Fig. <span class="scholmd-crossref"><a href="#straightTubeTestsVolumeDomain">(14)</a></span> shows that the dual lattice algorithm performs no worse than the single lattice algorithm.</p>
<figure class="scholmd-float scholmd-figure" id="straightTubeTestsVolumeDomain">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/testResults/scalarAbsorbedTest/straightTubeTestsVolumeDomain.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">a</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: ">
<img src="./dualLattice/testResults/scalarAbsorbedTest/straightTubeTestsVolumeDomainZoom.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">b</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">14</span></span><span class="scholmd-caption-text">Comparison of total volume of the domain per unit disk area for a cylinder of varying radius with the single and dual lattice algorithms. The straight line is the analytical solution. (a) Full range of radii; (b) Zoomed in.</span></figcaption></div>
</figure>
<h1 id="particle-tracking">Particle tracking</h1>
<p>The current procedure for particle tracking only uses data from 1 mesh. In the dual lattice algorithm, the particles could move from the coarse mesh. When this happens, if it were just an issue of using a different velocity field in the fine mesh, I could just update the <code>Interpolate_Parvel</code> function. However, the time-stepping algorithm itself needs to change such that the particle is now time-stepped using the time step corresponding to the fine mesh and not the coarse mesh. Hence, I’ll have to check whether the particle is in the fine mesh or the coarse mesh before the time-stepping procedure is carried out. I expect the time-stepping subroutine to be called after the streaming step in both the coarse and the fine mesh. Both subroutines will loop over the same set of particles. However, the bulk of the procedure for a given particle will be carried out only if the particle is in the corresponding region. Hence there will be two subroutines <code>Particle_Track</code> and <code>Particle_Track_fine</code>; similarly <code>Interp_Parvel</code> and <code>Interp_Parvel_fine</code> as well. The check for whether the particle is inside the fine mesh could be easily accomplished as</p>
<pre class="fortran90"><code>      hardCheckCoarseMesh = ( (current%pardata%xp - fractionDfine * D * 0.5 - xcf) * (current%pardata%xp + fractionDfine * D * 0.5 + xcf) &gt; 0 ) .or. ( (current%pardata%yp - fractionDfine * D * 0.5 - ycf) * (current%pardata%yp + fractionDfine * D * 0.5 + ycf) &gt; 0 )
      softCheckCoarseMesh = ( (current%pardata%xp - fractionDfine * D * 0.5 - (gridRatio-1)*xcf_fine) * (current%pardata%xp + fractionDfine * D * 0.5 + (gridRatio-1)*xcf_fine) &gt; 0 ) .or. ( (current%pardata%yp - fractionDfine * D * 0.5 - (gridRatio-1)*ycf_fine) * (current%pardata%yp + fractionDfine * D * 0.5 + (gridRatio-1)*ycf_fine) &gt; 0 )
      xpNF = current%pardata%xp + current%pardata%up * tcf !Hypothetical new location of particle based on first order extrapolation
      ypNF = current%pardata%yp + current%pardata%vp * tcf !Hypothetical new location of particle based on first order extrapolation
      zpNF = current%pardata%zp + current%pardata%wp * tcf !Hypothetical new location of particle based on first order extrapolation
      hardCheckCoarseMeshNF = ( (xpNF - fractionDfine * D * 0.5 - xcf) * (xpNF + fractionDfine * D * 0.5 + xcf) &gt; 0 ) .or. ( (ypNF - fractionDfine * D * 0.5 - ycf) * (ypNF + fractionDfine * D * 0.5 + ycf) &gt; 0 )  !Check if the hypothetical new location of the particle is clearly in the coarse mesh.
      IF ( hardCheckCoarseMesh .or. (softCheckCoarseMesh .and. flagParticleCF(current%pardata%parid) .and. hardCheckCoarseMeshNF) ) THEN  !Check if particle is in coarse mesh. Also check if the particle is in the interface region and was previously in the fine mesh and is coming out of it.    
          flagParticleCF(current%pardata%parid) = .false. !PARTICLE IS IN COARSE MESH
      ELSE
          flagParticleCF(current%pardata%parid) = .true. !PARTICLE IS IN FINE MESH    
      END IF </code></pre>
<h2 id="second-order-runge-kutta-time-stepping-for-particle-movement">Second order Runge-Kutta time stepping for particle movement</h2>
<p>We use a second order Runge-Kutta method for time stepping for tracking the particle movement. 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation}
\label{secondOrderRungerKuttaParticeTracking}
\begin{aligned}
\left. \frac{d \vec{x}}{dt} \right |_{n+1/2} &amp;= \frac{\vec{x}_{n+1} - \vec{x}_n}{\Delta t} = \vec{v}_{n+1/2} = \frac{\vec{v}_{n+1} + \vec{v}_{n}}{2} \\
\vec{x}_{n+1} &amp;= \vec{x}_n + \Delta t \left ( \frac{\vec{v}_{n+1} + \vec{v}_{n}}{2} \right )
\end{aligned}
\end{equation}
\]</span>
 <span class="math scholmd-math-inline">\(\vec{v}_{n+1}\)</span> is first estimated as the velocity at <span class="math scholmd-math-inline">\(\vec{x} + \Delta t \; \vec{v}_n\)</span>, i.e., the velocity at the point the particle is estimated to be at uusing first order time stepping. However, once the updated particle position at <span class="math scholmd-math-inline">\(n+1\)</span> is estimated using second order time stepping, the velocity is interpolated to the particle location again.</p>
<h2 id="test-for-particle-tracking">Test for particle tracking</h2>
<p>The test for particle tracking is to run the LBM code without streaming, collision, macro or any such routine with a prescribed velocity profile and geometry and to make sure that the particle is able to go smoothly through the coarse to fine and fine to coarse mesh interface. I prescribe the velocity profile as 
<span class="math scholmd-math-display" style="display: block;">\[
\begin{equation}
\label{prescribedVelocityProfileParticleTrackTest}
u = 0, \; v = -0.1, \; w = 1.0 - r/R \; \textrm{in lattice units.}
\end{equation}
\]</span>
 The initial location of the particle is <code>(0.0003, 0.001, 0.0012)m</code> in a prescribed geometry of a straight tube of <span class="math scholmd-math-inline">\(R=0.005m\)</span>. If the particle were to get convected correctly, then it should go down from the coarse into to the fine mesh, emerge back into the coarse mesh and also wrap around the periodic boundary twice before hitting the bottom wall of the intestine. Figure <span class="scholmd-crossref"><a href="#particleTrackTest">(15)</a></span> shows that the particle trajectory computed by the dual lattice algorithm is exactly the same as predicted using a second-order Runge-Kutta time stepping in a separate code using the same velocity profile.</p>
<figure class="scholmd-float scholmd-figure" id="particleTrackTest">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/particleTrackingTest/particle1_yLocation.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">y location</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/particleTrackingTest/particle1_zLocation.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">z location</span></figcaption></div>
</figure><br /><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/particleTrackingTest/particle1_yLocationZoom.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">y location (zoomed in)</span></figcaption></div>
</figure><figure class="scholmd-subfig" style="display: inline-block; width: 49%">
<img src="./dualLattice/testResults/particleTrackingTest/particle1_zLocationZoom.png" />
<div class="scholmd-float-subcaption"><figcaption><span class="scholmd-caption-text">z location (zoomed in)</span></figcaption></div>
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">15</span></span></figcaption></div>
</figure>
<p>Caption: Comparison of the particle trajectory computed by the dual lattice algorithm with the analytical solution according to the velocity profile in Eq. <span class="scholmd-crossref"><span class="math scholmd-math-inline">\(\eqref{prescribedVelocityProfileParticleTrackTest}\)</span></span>. (a) y location; (b) z location; (c) and (d) are zoomed in versions of (a) and (b) respectively. The horizontal lines in (a) and (c) represent the interface between the coarse and the fine mesh.</p>
<h1 id="particle-dissolution-model">Particle dissolution model</h1>
<p>There are 2 parts to the implementation of the particle dissolution model. The first is to compute the effective bulk concentration <span class="math scholmd-math-inline">\(C_b\)</span> around the particle; the next is to distribute the drug release over one time step into the nodes in the effective volume surrounding the particle.</p>
<h2 id="calculation-of-bulk-concentration">Calculation of bulk concentration</h2>
<p>Our most modern implementation of the particle dissolution model as 3 cases for the computation of the bulk concentration:</p>
<ul>
<li><span class="math scholmd-math-inline">\(V_{eff} &lt; V_{mesh}\)</span> - Use the nearest 8 nodes to perform trilinear interpolation of the concentration field to the particle,</li>
<li><span class="math scholmd-math-inline">\(V_{mesh} &lt; V_{eff} &lt; 27 \; V_{mesh}\)</span> - Interpolate the concentration field to a set of 64 points surrounding the particle using trilinear interpolation at each point, then average the concentration from those 64 points,</li>
<li><span class="math scholmd-math-inline">\(V_{eff} &gt; 27 \; V_{mesh}\)</span> - Average the concentration in all the LBM nodes that overlap with the effective volume around the particle.</li>
</ul>
<p>The process of determining the bulk concentration for a particle is performed in a loop over the particles inside the <code>Particle_Track</code> subroutine. This checks whether the particle is in the coarse or the fine mesh. So it’s impossible that the bulk concentration for aparticle will be calculated twice. This is extremely important to handle cases when the particle is in the interface between the two meshes.</p>
<p>In the dual lattice case, the particle is deemed to be in the in the coarse mesh if it satisfies the hard check or the soft check + if it’s comping into the coarse mesh. When a particle is near the mesh interface, it could happen that the influence volume surrounding the particle crosses over to the other mesh. The process of computing the bulk concentration should be able to handle this.</p>
<p>The effect of scalar release by the drug particle on the concentration is added at the end of the collision step. The concentration field from the previous time step is used for the computation of the bulk concentration. In the dual lattice algorithm, it is important to be consistent in using the concentration field from the same time step. It would be incorrect to use the concentration from <span class="math scholmd-math-inline">\(t_{n+1}\)</span> in the coarse mesh when calculating the bulk concentration for a particle in the fine mesh at a tiem step between <span class="math scholmd-math-inline">\(t_n\)</span> and <span class="math scholmd-math-inline">\(t_{n+1}\)</span>. This problem may not occur when the particle is in the coarse mesh with an effective volume that cuts into the fine mesh.</p>
<p>Going back to the 3 cases described earlier, they can be extended to the dual lattice algorithm as</p>
<ul>
<li><span class="math scholmd-math-inline">\(V_{eff} &lt; V_{mesh}\)</span> - irrespective of which mesh the particle is at, as long as this condition is satisfied in that mesh, the computation of bulk concentration will not overlap between meshes.</li>
<li><span class="math scholmd-math-inline">\(V_{mesh} &lt; V_{eff} &lt; 27 \; V_{mesh}\)</span> - Some of the 64 points could be a part of the other mesh. Just perform a check on whether each of the 64 points belongs to the coarse or the fine mesh and use the corresponding mesh to interpolate the concentration.</li>
<li><span class="math scholmd-math-inline">\(V_{eff} &gt; 27 \; V_{mesh}\)</span> - Volume average over all overlapping nodes. Also use the overlap number already computed for the coarse mesh nodes, the same one used for the computation of the total scalar in the domain.</li>
</ul>
<h2 id="distribution-of-drug-relase-to-lbm-nodes">Distribution of drug relase to LBM nodes</h2>
<p>In the original single lattice code, the time-stepping algorithm started from the post-streaming density distribution at <span class="math scholmd-math-inline">\(t_n\)</span> and ended with the post-streaming density distribution at the next time step <span class="math scholmd-math-inline">\(t_{n+1}\)</span>. The outline of the algorithm that is related to the particle tracking and drug release looked as follows.</p>
<pre class="fortran90"><code>DO iter = iter0-0_lng,nt

      CALL Advance_Geometry
      CALL Collision        ! collision step [MODULE: Algorithm]
      CALL MPI_Transfer     ! transfer the data (distribution functions, density, scalar) 

      CALL Particle_Track - Update particle location, interpolate bulk concentration to new particle location, calculate drug release and distribution to nodes
      CALL Stream           ! perform the streaming operation (with Lallemand 2nd order BB) 
      CALL Macro            ! calcuate the macroscopic quantities 

      CALL Scalar           ! calcuate the evolution of scalar in the domain and add the drug release calculated in Particle_Track
END DO</code></pre>
<p>While the model of calculating the drug release based on scalar concentration from the previous time step seems ok, I don’t quite understand the particle trakcing mechanism. The <code>Particle_Track</code> routine is called before the streaming and macro steps; this means that <code>Particle_Track</code> will never use the updated velocity that it’s supposed to in Eq. <span class="scholmd-crossref"><span class="math scholmd-math-inline">\(\eqref{secondOrderRungerKuttaParticeTracking}\)</span></span>. The drug release model uses the scalar concentration from the previous time step. It also calculates the distribution of the drug release to the neighboring nodes and adds it when going through the <code>Scalar</code> subroutine.</p>
<p>I’ve since changed the outline of LBM algorithm and re-ordered some of the steps. In particular, the new method starts with the post-collision density-distribution at time step <span class="math scholmd-math-inline">\(t_n\)</span> and ends with the post-collision density distribution at the next time step <span class="math scholmd-math-inline">\(t_{n+1}\)</span>. The new algorithm looks as follows.</p>
<pre class="fortran90"><code>DO iter = iter0-0_lng,nt

      CALL Advance_Geometry
      CALL Stream           ! perform the streaming operation (with Lallemand 2nd order BB) 
      CALL Macro            ! calcuate the macroscopic quantities 

      CALL Particle_Track - Update particle location, interpolate bulk concentration to new particle location, calculate drug release and distribution to nodes
      CALL Scalar           ! calcuate the evolution of scalar in the domain and add the drug release calculated in Particle_Track
      CALL Collision        ! collision step 
      CALL MPI_Transfer     ! transfer the data (distribution functions, density, scalar) 

END DO</code></pre>
<p>This way, the <code>Particle_Track</code> subroutine is able to use the average of the old and the updated velocity correctly as described in Eq. <span class="scholmd-crossref"><span class="math scholmd-math-inline">\(\eqref{secondOrderRungerKuttaParticeTracking}\)</span></span>. However, the calculation of the bulk concentration for the drug release is still from the previous time step, the same as it was in the previous algorithm design. In principle, This could’ve been achieved by merely moving the <code>Particle_Track</code> subroutine call to after the streaming step in the previous algorithm design. However, the new algorithm design suits the dual lattice algorithm better in my opinion and is consistent with the way Yanxing designed his dual lattice algorithm.</p>
<p>The rough outline of the dual lattice algorithm that is related to the particle tracking and drug release from particles looks like</p>
<pre class="fortran90"><code>DO iter = iter0-0_lng,nt

      CALL Advance_Geometry
      CALL Stream           ! perform the streaming operation (with Lallemand 2nd order BB) 
      CALL Macro            ! calcuate the macroscopic quantities 

      CALL Particle_Track - Update particle location for those in the coarse mesh, interpolate bulk concentration to new particle location, calculate drug release and distribution to nodes
      CALL Scalar           ! calcuate the evolution of scalar in the domain and add the drug release calculated in Particle_Track
      phi_fine = phi_fine + delphi_fine !Add the drug release corresponding to any particle in the coarse mesh whose effective volume interfaces with the fine mesh
      CALL Collision        ! collision step 
      CALL MPI_Transfer     ! transfer the data (distribution functions, density, scalar) [MODULE: Parallel]

      CALL SpatialInterpolateToFineGrid      ! Interpolate required variables to fine grid

      DO subIter=1,ratio
          CALL AdvanceGeometry_Fine   ! Advance the geometry on the fine grid
          CALL TemporalInterpolateToFineGrid
          CALL Stream_Fine            ! Stream fine grid
          CALL Macro_Fine             ! Calculate Macro properties on fine grid

          CALL Particle_Track_fine - Update particle location for those in the fine mesh, interpolate bulk concentration to new particle location, calculate drug release and distribution to nodes
          if(max(delphi) .gt. 0) then
              phi = phi + delphi
              CALL SpatialInterpolatePhiToFineGrid      ! Interpolate phi alone to fine grid
          end if
          CALL Scalar_Fine       ! Calculate Scalar stuff on fine grid
          
          CALL Collision_Fine     ! Collision step on the fine grid
          CALL MPI_Transfer_Fine  ! Transfer the data across processor boundaries on the fine grid
      END DO
      CALL InterpolateToCoarseGrid    ! Interpolate required variable to coarse grid

END DO
</code></pre>
<p>When a particle is in the coarse mesh, but it’s effective volume overlaps with the fine mesh, then the treatment of <code>delphi_fine</code> that needs to be added to the scalar in the fine mesh can be tricky. Technically it needs to be added uniformly over the time steps in the fine mesh and the same way. However, this would require declaring an entire array called <code>delphi_fineFromCoarse</code> just for this purpose. If this is not done, then there would be two errors:</p>
<ul>
<li>the entire scalar to be added over <code>gridRatio</code> number of time steps in the fine mesh would be dumped over just the first fine mesh time step. This could cause local spikes in concentration that would get transported and diffused over the subsequent <code>gridRatio-1</code> time steps.</li>
<li>the order of adding the <code>delphi_fine</code> would be changed, i.e. while the <code>delphi_fine</code> is currently added after the moment-propagation method performs the collision and transport, the new method would add the <code>delphi_fine</code> before the moment-propagation method. I have no idea if this is correct or not; I just thought I’ll make a note of this in case this comes up later<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</li>
</ul>
<p>Similarly, when a particle is in the fine mesh, but it’s effective volume overlaps with the coarse mesh, then the treatment of <code>delphi</code> that needs to be added to the scalar in the fine mesh can be tricky. Technically, it’s supposed to be added at the intermediate time steps; however, the coarse mesh does not have that kind of time resolution. Hence it is added to the <code>phi</code> at time step <span class="math scholmd-math-inline">\(t_{n+1}\)</span> instead. The whole point of doing this addition at every fine mesh time step and not waiting till the end of all the fine mesh time steps is that this could potentially affect the calculation of the bulk concentration for the particle. Hence, this drug release will change the value of the scalar concentration on the boundary. This implies that the spatial interpolation of the scalar concentration from the coarse to the fine mesh needs to be performed again around the points where the scalar concentration has changed on the coarse mesh. Performing this check could be as expensive or of the same order as just doing the full interpolation again. I think I’ll just do the full interpolation again, but just for the scalar alone.</p>
<h2 id="testing-of-particle-dissolution-model">Testing of particle dissolution model</h2>
<p>I tested the implementation of the particle dissolution model by performing the following test. I use the geometry of the straight tube of radius <span class="math scholmd-math-inline">\(5mm\)</span>. I initialize the velocity field such that the axial velocity is 1 in lattice units and all other velocity components are zero. I turn off Collision, Streaming and Scalar evolution and retain only the particle release model. Thus the particle should travel in a straight line and release drug. Fig. <span class="scholmd-crossref"><a href="#particleDissolutionTest">(16)</a></span> shows the evolution of the bulk concentration <span class="math scholmd-math-inline">\(C_b\)</span> and the drug release <span class="math scholmd-math-inline">\(\Delta N_b\)</span> as a function of time. It seems to behave along expected lines, i.e., the <span class="math scholmd-math-inline">\(C_b\)</span> increases first before attaining a quasi-steady state. Once the particle starts to go over the same area where it has already released drug, the <span class="math scholmd-math-inline">\(C_b\)</span> increases and <span class="math scholmd-math-inline">\(\Delta N_b\)</span> reduces. I repeat this test for 4 different cases, viz.,</p>
<ul>
<li>the particle is completely in the coarse mesh,</li>
<li>the particle is in the coarse mesh, but it’s effective volume straddles the fine mesh,</li>
<li>the particle is in the fine mesh, but it’s effective volume straddles the coarse mesh,</li>
<li>the particle is completely in the fine mesh.</li>
</ul>
<p>The difference in the computed <span class="math scholmd-math-inline">\(C_b\)</span> between when the particle is completely in the fine mesh and completely in the coarse mesh is about <span class="math scholmd-math-inline">\(12\%\)</span>.</p>
<p>While this is not a validation of the method working correctly.</p>
<figure class="scholmd-float scholmd-figure" id="particleDissolutionTest">
<div class="scholmd-float-content"><figure class="scholmd-subfig" style="display: inline-block; width: 75%">
<img src="./dualLattice/testResults/particleDissolutionTest/cbnb.png" />
</figure></div>
<div class="scholmd-float-caption"><figcaption><span class="scholmd-caption-head"><span class="scholmd-caption-head-prefix">Figure</span><span class="scholmd-caption-head-label">16</span></span><span class="scholmd-caption-text">Testing of particle dissolution model.</span></figcaption></div>
</figure>
<h1 id="future-work-over-the-next-two-weeks">Future work over the next two weeks</h1>
<ul>
<li>Write up
<ul>
<li>How are cases of wall interference handled during spatial and temporal interpolation</li>
</ul></li>
<li>Particle tracking and dissolution
<ul>
<li>Reintroduction of drug dissolution model
<ul>
<li>How to calculate bulk concentration when the particle is in the mesh interface?</li>
<li>How to calculate drug release distribution when the particle is in the mesh interface?</li>
<li>How to introduce the new models for both into this code?</li>
<li>Parallelization</li>
</ul></li>
</ul></li>
</ul>
<div class="references">

</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>In a related discussion, Farhad noted that the order of adding the <code>delphi</code> is important and doing so before the moment propagation method could potentially reduce the negative scalar problems.<a href="#fnref1">↩</a></p></li>
</ol>
</section>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
      processClass: "math"
    },
    TeX: {
        TagSide: "left",
        TagIndent: "1.2em",
        equationNumbers: {
            autoNumber: "AMS"
        },
        Macros: {
            ensuremath: ["#1",1],
            textsf: ["\\mathsf{\\text{#1}}",1],
            texttt: ["\\mathtt{\\text{#1}}",1]
        }
    },
    "HTML-CSS": { 
        scale: 100,
        availableFonts: ["TeX"], 
        preferredFont: "TeX",
        webFont: "TeX",
        imageFont: "TeX",
        EqnChunk: 1000
    }
});
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML-full" type="text/javascript"></script>
</div>
</body>
</html>
